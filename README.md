

兩個自然語言處理實作專案的核心 傳統序列模型 與 現代語意模型 的實際案例。

---

### 🧠 專案總覽比較

|             | 使用模型             | 資料語言 | 實作操作                                         | 目標                        |
|------------------------|-----------------------|----------|----------------------------------------------------------|-------------------------------------|
| AINLP 期末專題          | Transformer / BERT    | 中文     | 預訓練語言模型、微調（Fine-tuning）、Token 分詞、分類           | 判斷兩句中文句子是否語意相近         |
| IMDB 情緒分析專題       | RNN / LSTM（手刻模型）| 英文     | 序列建模、詞嵌入（Embedding）、Padding、二元情緒分類            | 分析英文電影評論為正向或負向         |

---

###

####  AINLP 期末專題（中文語義判斷）

- 採用 **Hugging Face Transformers** 套件
- 載入 `bert-base-chinese` 預訓練模型並微調（fine-tune）
- 處理中文句子對，判斷其語義是否相似
- 包含資料清理、欄位轉換、分詞與模型包裝
- 模型輸出為 0 / 1 表示是否語意相近，並可生成 `submission.csv`

####  RNN / LSTM IMDB 情緒分析

- 使用 `tf.keras.datasets.imdb` 內建英文影評資料集
- 嘗試兩種模型：`SimpleRNN` 與 `LSTM`
- 將文字轉成索引序列，並進行 Padding 與詞嵌入
- 使用 Sigmoid 激活進行二元情緒分類（0 = 負評，1 = 正評）
- 顯示訓練損失 / 準確率曲線並支援使用者自訂輸入推論

---

####


---

